{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fe12c203-e6a6-452c-a655-afb8a03a4ff5",
   "metadata": {},
   "source": [
    "# End of week 1 exercise\n",
    "\n",
    "To demonstrate your familiarity with OpenAI API, and also Ollama, build a tool that takes a technical question,  \n",
    "and responds with an explanation. This is a tool that you will be able to use yourself during the course!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c1070317-3ed9-4659-abe3-828943230e03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import os\n",
    "from dotenv import load_dotenv\n",
    "from IPython.display import Markdown, display, update_display\n",
    "from openai import OpenAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c9014df8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize and constants\n",
    "load_dotenv(override=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a456906-915a-4bfd-bb9d-57e505c5093f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initializing GPT\n",
    "\n",
    "MODEL_GPT = os.getenv(\"MODEL_GPT\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "afb6245c-6658-4f8c-84bb-d913a2c77bdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠋ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠙ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠹ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠸ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠼ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest ⠴ \u001b[K\u001b[?25h\u001b[?2026l\u001b[?2026h\u001b[?25l\u001b[1Gpulling manifest \u001b[K\n",
      "pulling dde5aa3fc5ff: 100% ▕██████████████████▏ 2.0 GB                         \u001b[K\n",
      "pulling 966de95ca8a6: 100% ▕██████████████████▏ 1.4 KB                         \u001b[K\n",
      "pulling fcc5a6bec9da: 100% ▕██████████████████▏ 7.7 KB                         \u001b[K\n",
      "pulling a70ff7e570d9: 100% ▕██████████████████▏ 6.0 KB                         \u001b[K\n",
      "pulling 56bb8bd477a5: 100% ▕██████████████████▏   96 B                         \u001b[K\n",
      "pulling 34bb5ab01051: 100% ▕██████████████████▏  561 B                         \u001b[K\n",
      "verifying sha256 digest \u001b[K\n",
      "writing manifest \u001b[K\n",
      "success \u001b[K\u001b[?25h\u001b[?2026l\n"
     ]
    }
   ],
   "source": [
    "# Initializing LLAMA \n",
    "\n",
    "MODEL_LLAMA = os.getenv(\"OLLAMA_MODEL\")\n",
    "OLLAMA_BASE_URL = os.getenv(\"OLLAMA_BASE_URL\") \n",
    "OLLAMA_API_KEY = os.getenv(\"OLLAMA_API_KEY\")\n",
    "\n",
    "ollama_via_openai = OpenAI(base_url=OLLAMA_BASE_URL, api_key=OLLAMA_API_KEY)\n",
    "!ollama pull llama3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a8d7923c-5f28-4c30-8556-342d7c8497c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "API key looks good so far\n"
     ]
    }
   ],
   "source": [
    "# Set up the environment\n",
    "\n",
    "api_key = os.getenv('OPENAI_API_KEY')\n",
    "\n",
    "if api_key and api_key.startswith('sk-proj-') and len(api_key)>10:\n",
    "    print(\"API key looks good so far\")\n",
    "else:\n",
    "    print(\"There might be a problem with your API key? Please visit the troubleshooting notebook!\")\n",
    "    \n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0c817434-576f-4bee-8658-e4f8eee64cdf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the system prompt\n",
    "system_prompt = \"You are a coding assistant the answers questions about small code snippets in a \\\n",
    "very insightful and illustrative way, giving examples and explaining how these concepts are embedded \\\n",
    "in a broader context. Stay away from 'talking' to the user, just inform them like a wikipedia article. \\\n",
    "Create the output as Markdown. Whenever possible, show examples in 'code' formatted boxes.\"\n",
    "system_prompt += \"\"\"\n",
    "An example for this last requirement would be: \\\n",
    "```python\n",
    "    def example_function():\n",
    "```\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3f0d0137-52b0-47a8-81a8-11a90a010798",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Please explain what this code does and why:\n",
      "\n",
      "yield from {book.get(\"author\") for book in books if book.get(\"author\")}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# here is the question; type over this to ask something new\n",
    "\n",
    "example_snippet = 'yield from {book.get(\"author\") for book in books if book.get(\"author\")}'\n",
    "\n",
    "def get_user_prompt(snippet):\n",
    "    user_prompt = \"Please explain what this code does and why:\\n\\n\"\n",
    "    user_prompt += snippet\n",
    "    user_prompt += \"\\n\"\n",
    "    return user_prompt\n",
    "print(get_user_prompt(example_snippet))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb4478b3-a68e-4b06-a3f9-2b8568345634",
   "metadata": {},
   "outputs": [],
   "source": [
    "def handle_stream(stream_response):\n",
    "    response = \"\"\n",
    "    display_handle = display(Markdown(\"\"), display_id=True)\n",
    "    for chunk in stream_response:\n",
    "        response += chunk.choices[0].delta.content or ''\n",
    "        update_display(Markdown(response), display_id=display_handle.display_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "0f60818e-5ae7-461e-814c-89518be81dcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model_handler(model):\n",
    "    def coding_answer(code_snippet, system_prompt):\n",
    "        user_prompt = get_user_prompt(code_snippet)\n",
    "        \n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": system_prompt},\n",
    "            {\"role\": \"user\", \"content\": user_prompt}\n",
    "        ]\n",
    "        \n",
    "        if model.startswith(\"llama\"):\n",
    "            # Handle Ollama models\n",
    "            response = ollama_via_openai.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages\n",
    "            )\n",
    "            return display(Markdown(response.choices[0].message.content))\n",
    "        else:\n",
    "            # Handle OpenAI models\n",
    "            stream = openai.chat.completions.create(\n",
    "                model=model,\n",
    "                messages=messages,\n",
    "                stream=True\n",
    "            )\n",
    "            return handle_stream(stream)\n",
    "    \n",
    "    return coding_answer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "873baa3b-e89c-4fb4-8621-2c8445309efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama_coder = create_model_handler(MODEL_LLAMA)\n",
    "openai_coder = create_model_handler(MODEL_GPT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b5d9ed93-4707-42ce-8711-6e91a3687051",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Example Code Explanation**\n",
       "\n",
       "```python\n",
       "def author_generator(books):\n",
       "    yield from {book[\"author\"] for book in books if \"author\" in book}\n",
       "```\n",
       "\n",
       "**Purpose**\n",
       "--------\n",
       "\n",
       "The code snippet defines a generator function called `author_generator` that yields the authors of books stored in a list (`books`). The authors are extracted based on the presence of the key `\"author\"` within each book dictionary.\n",
       "\n",
       "**Code Breakdown**\n",
       "\n",
       "*   `yield from`: This keyword is used to delegate iteration to another iterable (in this case, a dictionary comprehension). It allows us to produce a collection of results without loading them all into memory at once.\n",
       "*   `{... for book in books if book.get(\"author\")}`: A dictionary comprehension that iterates over the list of books (`books`). For each book:\n",
       "    *   `if book.get(\"author\")`: This condition filters out books that do not have an `\"author\"` key. The `get()` method returns a value or `None` if the key does not exist, preventing a KeyError.\n",
       "    *   `{book[\"author\"]}`: If the book has an `\"author\"` key, this expression extracts its value.\n",
       "\n",
       "**How it Works**\n",
       "\n",
       "1.  Initialize an empty list (`books`) that contains dictionaries representing books with their respective authors.\n",
       "2.  Call the `author_generator` function and iterate over the resulting iterable of authors using a for-each loop or another context manager.\n",
       "3.  The generator will produce one author at a time, yielding it to the caller.\n",
       "\n",
       "**Example Use Case**\n",
       "\n",
       "```python\n",
       "books = [\n",
       "    {\"title\": \"Book 1\", \"author\": \"Author A\"},\n",
       "    {\"title\": \"Book 2\"},  # Missing author key\n",
       "    {\"title\": \"Book 3\", \"author\": \"Author C\"}\n",
       "]\n",
       "\n",
       "for author in author_generator(books):\n",
       "    print(author)\n",
       "# Output:\n",
       "# Author A\n",
       "# Author C\n",
       "```\n",
       "\n",
       "In this example, the generator function `author_generator` is used to extract and yield only the authors of books that have an `\"author\"` key. The resulting iterable is iterated over using a for-each loop, printing each author as it becomes available."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get Llama 3.2 to answer\n",
    "ollama_response = ollama_coder(example_snippet, system_prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "60ce7000-a4a5-4cce-a261-e75ef45063b4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "The provided code snippet utilizes a combination of the `yield from` statement, a set comprehension, and conditional filtering. Here's a breakdown of its components and their purpose:\n",
       "\n",
       "### Breakdown of the Code\n",
       "\n",
       "1. **Set Comprehension**:\n",
       "   - `{book.get(\"author\") for book in books if book.get(\"author\")}` is a set comprehension that iterates over a collection named `books`.\n",
       "   - Each `book` is expected to be a dictionary, and it attempts to retrieve the value associated with the key `\"author\"` using the `get` method. \n",
       "   - The condition `if book.get(\"author\")` ensures that only books with a non-`None` or non-empty string author will be included in the resulting set. This prevents `None` or empty strings from being added.\n",
       "\n",
       "   #### Example:\n",
       "   Given the following list of books:\n",
       "   ```python\n",
       "   books = [\n",
       "       {\"title\": \"Book A\", \"author\": \"Author 1\"},\n",
       "       {\"title\": \"Book B\", \"author\": None},\n",
       "       {\"title\": \"Book C\", \"author\": \"Author 2\"},\n",
       "       {\"title\": \"Book D\", \"author\": \"\"},\n",
       "       {\"title\": \"Book E\"}\n",
       "   ]\n",
       "   ```\n",
       "   The set comprehension would result in:\n",
       "   ```python\n",
       "   {\"Author 1\", \"Author 2\"}\n",
       "   ```\n",
       "\n",
       "2. **`yield from` Statement**:\n",
       "   - `yield from <iterable>` is used within a generator function to yield all the values from the specified iterable (`{...}` in this case).\n",
       "   - This statement simplifies the process of yielding multiple values from another iterable, making the generator code cleaner and more readable.\n",
       "\n",
       "3. **Overall Purpose**:\n",
       "   - The entire expression `yield from {book.get(\"author\") for book in books if book.get(\"author\")}` is likely located inside a generator function. Its main purpose is to yield each unique author from the provided collection of books, while ignoring any entries that do not have a valid author.\n",
       "\n",
       "### Contextual Usage\n",
       "This kind of code is particularly useful in situations where a large collection of records needs to be processed, particularly in applications dealing with data extraction or manipulation, such as:\n",
       "\n",
       "- **Data Analysis**: Extracting unique authors from a dataset before analyzing their publications.\n",
       "- **APIs**: Collecting unique author information to return in a response.\n",
       "- **Text Processing**: Compiling lists of contributors to a collection of works.\n",
       "\n",
       "### Conclusion\n",
       "The code snippet effectively filters and extracts unique author names from a given list of book dictionaries, leveraging Python's capabilities for clean and efficient data processing through set comprehensions and generator functions."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Get gpt-4o-mini to answer, with streaming\n",
    "openai_response = openai_coder(example_snippet, system_prompt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llms",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
